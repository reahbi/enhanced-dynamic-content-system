"""
ì½˜í…ì¸  ìƒì„± API ì—”ë“œí¬ì¸íŠ¸
"""

from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks, Query
from typing import List, Dict, Any, Optional
from datetime import datetime
from pydantic import BaseModel, Field
from enum import Enum
import json
from sqlalchemy.orm import Session

from ..models.database import get_db, Content as ContentModel, Category as CategoryModel, Paper as PaperModel

from ..services.advanced_cache_manager import advanced_cache
from ..services.performance_optimizer import performance_optimizer
from ..services.thinking.native_thinking_engine import NativeThinkingEngine
from ..services.content_generators.article_generator import ArticleGenerator
from ..services.content_generators.report_generator import ReportGenerator
from ..utils.logging_config import app_logger, audit_logger
from ..utils.token_tracker import token_tracker

router = APIRouter()

# Enums
class ContentType(str, Enum):
    ARTICLE = "article"
    REPORT = "report"

class ThinkingMode(str, Enum):
    NONE = "none"
    BASIC = "basic"
    ENHANCED = "enhanced"

# Pydantic ëª¨ë¸
class ContentRequest(BaseModel):
    """ì½˜í…ì¸  ìƒì„± ìš”ì²­"""
    topic: str = Field(..., min_length=1, max_length=200, description="ì½˜í…ì¸  ì£¼ì œ")
    category_id: str = Field(..., description="ì¹´í…Œê³ ë¦¬ ID")
    content_type: ContentType = Field(..., description="ì½˜í…ì¸  íƒ€ì…")
    paper_ids: List[str] = Field(..., min_items=1, max_items=10, description="ë…¼ë¬¸ ID ëª©ë¡")
    thinking_mode: ThinkingMode = Field(default=ThinkingMode.ENHANCED, description="ì‚¬ê³  ëª¨ë“œ")
    additional_context: Optional[str] = Field(None, description="ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸")

class GeneratedContent(BaseModel):
    """ìƒì„±ëœ ì½˜í…ì¸ """
    id: str
    topic: str
    category_id: str
    content_type: ContentType
    content: str
    metadata: Dict[str, Any]
    quality_score: float
    thinking_process: Optional[str]
    created_at: str

class ContentResponse(BaseModel):
    """ì½˜í…ì¸  ì‘ë‹µ"""
    content: GeneratedContent
    generation_time: float
    cache_hit: bool

class ContentListResponse(BaseModel):
    """ì½˜í…ì¸  ëª©ë¡ ì‘ë‹µ"""
    contents: List[GeneratedContent]
    total: int
    filters_applied: Dict[str, Any]

class TransformationType(str, Enum):
    """ì½˜í…ì¸  ë³€í™˜ íƒ€ì…"""
    HUMANIZE = "humanize"  # ì‚¬ëŒì´ ì“´ ê²ƒì²˜ëŸ¼
    SIMPLIFY = "simplify"  # ì‰½ê²Œ ì„¤ëª…
    PRACTICAL = "practical"  # ì‹¤ìš©ì ìœ¼ë¡œ
    NATURAL_FORMAT = "natural_format"  # ìì—°ìŠ¤ëŸ¬ìš´ ì„œì‹ìœ¼ë¡œ

class ContentTransformRequest(BaseModel):
    """ì½˜í…ì¸  ë³€í™˜ ìš”ì²­"""
    content_id: str = Field(..., description="ë³€í™˜í•  ì½˜í…ì¸  ID")
    transformation_type: TransformationType = Field(..., description="ë³€í™˜ íƒ€ì…")

class BatchContentRequest(BaseModel):
    """ë°°ì¹˜ ì½˜í…ì¸  ìƒì„± ìš”ì²­"""
    requests: List[ContentRequest] = Field(..., min_items=1, max_items=10)

# ì˜ì¡´ì„±
def get_thinking_engine():
    """Native Thinking Engine ì¸ìŠ¤í„´ìŠ¤"""
    return NativeThinkingEngine()

def get_content_generators():
    """ì½˜í…ì¸  ìƒì„±ê¸° ì¸ìŠ¤í„´ìŠ¤ë“¤"""
    return {
        ContentType.ARTICLE: ArticleGenerator(),
        ContentType.REPORT: ReportGenerator()
    }

@router.post("/generate", response_model=ContentResponse)
@performance_optimizer.measure_performance("content_generation")
async def generate_content(
    request: ContentRequest,
    thinking_engine: NativeThinkingEngine = Depends(get_thinking_engine),
    generators: Dict[ContentType, Any] = Depends(get_content_generators),
    db: Session = Depends(get_db)
):
    """ì½˜í…ì¸  ìƒì„±"""
    try:
        start_time = datetime.now()
        
        # í† í° ì¶”ì ê¸° ì´ˆê¸°í™” (ìƒˆ ì½˜í…ì¸  ìƒì„± ì›Œí¬í”Œë¡œìš°)
        token_tracker.reset()
        
        # ìºì‹œ í™•ì¸
        cache_key = f"content_{hash(str(request.dict()))}"
        cached_content = advanced_cache.get(cache_key)
        
        if cached_content:
            app_logger.info(f"ìºì‹œì—ì„œ ì½˜í…ì¸  ë°˜í™˜: {request.topic}")
            return ContentResponse(
                content=cached_content,
                generation_time=0.0,
                cache_hit=True
            )
        
        # ë…¼ë¬¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (additional_contextì—ì„œ ì¶”ì¶œ)
        papers = []
        try:
            if request.additional_context:
                context_data = json.loads(request.additional_context)
                if 'papers' in context_data:
                    papers = context_data['papers']
                else:
                    raise HTTPException(
                        status_code=400,
                        detail="ë…¼ë¬¸ ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë…¼ë¬¸ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”."
                    )
            else:
                raise HTTPException(
                    status_code=400,
                    detail="ë…¼ë¬¸ ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € ë…¼ë¬¸ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”."
                )
        except json.JSONDecodeError:
            app_logger.error("additional_context JSON íŒŒì‹± ì‹¤íŒ¨")
            raise HTTPException(
                status_code=400,
                detail="ì˜ëª»ëœ ë…¼ë¬¸ ì •ë³´ í˜•ì‹ì…ë‹ˆë‹¤."
            )
        
        # ìƒì„±ê¸° ì„ íƒ
        generator = generators.get(request.content_type)
        if not generator:
            raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” ì½˜í…ì¸  íƒ€ì…ì…ë‹ˆë‹¤")
        
        # ì½˜í…ì¸  ìƒì„±
        generated_content = generator.generate(
            topic=request.topic,
            papers=papers,
            category_id=request.category_id,
            additional_context=request.additional_context
        )
        
        # í’ˆì§ˆ í‰ê°€
        quality_score = generated_content.quality_score
        
        # Thinking Mode ì ìš©
        thinking_process = None
        if request.thinking_mode != ThinkingMode.NONE:
            thinking_result = thinking_engine.generate_with_thinking(
                prompt=f"Analyze the quality and impact of this {request.content_type} content about {request.topic}",
                require_thinking=(request.thinking_mode == ThinkingMode.ENHANCED)
            )
            thinking_process = thinking_result.thinking_process
            
            # ì‚¬ê³  ê³¼ì • ê¸°ë°˜ í’ˆì§ˆ ì ìˆ˜ ì¡°ì •
            if thinking_result.thinking_quality_score > 0.8:
                quality_score = min(100, quality_score * 1.1)
        
        # ê²°ê³¼ ìƒì„±
        content_id = f"cnt_{datetime.now().strftime('%Y%m%d%H%M%S')}_{hash(request.topic) % 10000}"
        
        # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
        metadata = {
            "tone": generated_content.tone,
            "word_count": len(generated_content.content.split()) if generated_content.content else 0,
            "paper_count": len(papers),
            "generation_method": generator.__class__.__name__,
            "papers": papers  # ë…¼ë¬¸ ì •ë³´ ì¶”ê°€
        }
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        db_content = ContentModel(
            id=content_id,
            topic=request.topic,
            category_id=request.category_id,
            paper_id=request.paper_ids[0] if request.paper_ids else None,  # ì²« ë²ˆì§¸ ë…¼ë¬¸ ID ì‚¬ìš©
            content_type=request.content_type.value,
            content=generated_content.content,
            content_metadata=json.dumps(metadata),  # JSONìœ¼ë¡œ ì§ë ¬í™”
            thinking_process=thinking_process,
            quality_score=quality_score
        )
        
        db.add(db_content)
        db.commit()
        db.refresh(db_content)
        
        app_logger.info(f"ì½˜í…ì¸  ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {content_id}")
        
        # API ì‘ë‹µìš© ê°ì²´ ìƒì„±
        result = GeneratedContent(
            id=content_id,
            topic=request.topic,
            category_id=request.category_id,
            content_type=request.content_type,
            content=generated_content.content,
            metadata=metadata,
            quality_score=quality_score,
            thinking_process=thinking_process,
            created_at=db_content.created_at.isoformat()
        )
        
        # ìºì‹œ ì €ì¥
        advanced_cache.set(
            cache_key, 
            result,
            ttl=3600*24,  # 24ì‹œê°„
            metadata={
                "content_type": request.content_type.value,
                "quality_score": quality_score,
                "topic": request.topic
            }
        )
        
        # ê°œë³„ ì½˜í…ì¸  íƒ€ì…ë³„ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì‹œ í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
        # ì¹´í…Œê³ ë¦¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        category = db.query(CategoryModel).filter(CategoryModel.id == request.category_id).first()
        category_name = category.name if category else "Unknown Category"
        
        # ê° ì½˜í…ì¸  íƒ€ì…ë³„ë¡œ ìš”ì•½
        token_tracker.log_workflow_summary(
            f"Content Generation Workflow - {category_name} / {request.topic} ({request.content_type.value})"
        )
        
        # report ìƒì„± í›„ ì „ì²´ ì›Œí¬í”Œë¡œìš° í† í° ì‚¬ìš©ëŸ‰ ì´í•© ë¡œê¹…
        if request.content_type == ContentType.REPORT:
            # ì•½ê°„ì˜ ì§€ì—°ì„ ë‘ê³  ì „ì²´ ìš”ì•½ (ëª¨ë“  ê°œë³„ ìš”ì•½ì´ ëë‚œ í›„)
            import asyncio
            await asyncio.sleep(0.1)
            
            app_logger.info("\n" + "="*80)
            app_logger.info("[TOTAL WORKFLOW SUMMARY] ì „ì²´ ì›Œí¬í”Œë¡œìš° í† í° ì‚¬ìš©ëŸ‰ ì´í•©")
            app_logger.info("="*80)
            
            # í˜„ì¬ ì„¸ì…˜ì˜ ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ ê³„ì‚°
            total_prompt_tokens = 0
            total_response_tokens = 0
            total_tokens = 0
            total_cost = 0.0
            
            for operation, usage in token_tracker.usage_by_operation.items():
                total_prompt_tokens += usage['prompt_tokens']
                total_response_tokens += usage['response_tokens']
                total_tokens += usage['total_tokens']
            
            # ë¹„ìš© ê³„ì‚°
            total_cost_krw = token_tracker._calculate_cost_krw(total_prompt_tokens, total_response_tokens)
            total_cost_usd = token_tracker._calculate_cost_usd(total_prompt_tokens, total_response_tokens)
            
            app_logger.info(f"ì „ì²´ í”„ë¡œì„¸ìŠ¤: ì¹´í…Œê³ ë¦¬ ìƒì„± â†’ ì„œë¸Œì¹´í…Œê³ ë¦¬ ìƒì„± â†’ ì½˜í…ì¸  ìƒì„± (shorts/article/report)")
            app_logger.info(f"ì´ ì‘ì—… ìˆ˜: {sum(usage['count'] for usage in token_tracker.usage_by_operation.values())}")
            app_logger.info(f"ì´ í† í° ì‚¬ìš©ëŸ‰: {total_tokens:,}")
            app_logger.info(f"  - ì…ë ¥ í† í°: {total_prompt_tokens:,}")
            app_logger.info(f"  - ì¶œë ¥ í† í°: {total_response_tokens:,}")
            app_logger.info(f"ì˜ˆìƒ ì´ ë¹„ìš©: ${total_cost_usd:,.4f} USD (â‚©{total_cost_krw:,.2f} KRW)")
            app_logger.info("="*80 + "\n")
        
        # ê°ì‚¬ ë¡œê¹…
        audit_logger.log_action(
            action="generate_content",
            entity_type="content",
            entity_id=content_id,
            changes={
                "topic": request.topic,
                "type": request.content_type.value,
                "quality_score": quality_score
            }
        )
        
        generation_time = (datetime.now() - start_time).total_seconds()
        
        return ContentResponse(
            content=result,
            generation_time=generation_time,
            cache_hit=False
        )
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ì½˜í…ì¸  ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@router.get("/list", response_model=ContentListResponse)
async def list_contents(
    content_type: Optional[ContentType] = None,
    category_id: Optional[str] = None,
    min_quality: Optional[float] = None,
    limit: int = 20,
    db: Session = Depends(get_db)
):
    """ìƒì„±ëœ ì½˜í…ì¸  ëª©ë¡ ì¡°íšŒ"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì½˜í…ì¸  ì¡°íšŒ
        query = db.query(ContentModel)
        
        # í•„í„°ë§
        if content_type:
            query = query.filter(ContentModel.content_type == content_type.value)
        if category_id:
            query = query.filter(ContentModel.category_id == category_id)
        if min_quality:
            query = query.filter(ContentModel.quality_score >= min_quality)
        
        # ìµœì‹ ìˆœ ì •ë ¬ ë° ì œí•œ
        db_contents = query.order_by(ContentModel.created_at.desc()).limit(limit).all()
        
        # GeneratedContent ê°ì²´ë¡œ ë³€í™˜
        contents = []
        for db_content in db_contents:
            metadata = json.loads(db_content.content_metadata) if db_content.content_metadata else {}
            
            content = GeneratedContent(
                id=db_content.id,
                topic=db_content.topic,
                category_id=db_content.category_id,
                content_type=db_content.content_type,
                content=db_content.content,
                metadata=metadata,
                quality_score=db_content.quality_score,
                thinking_process=db_content.thinking_process,
                created_at=db_content.created_at.isoformat()
            )
            contents.append(content)
        
        # ì „ì²´ ê°œìˆ˜ ì¡°íšŒ
        total_query = db.query(ContentModel)
        if content_type:
            total_query = total_query.filter(ContentModel.content_type == content_type.value)
        if category_id:
            total_query = total_query.filter(ContentModel.category_id == category_id)
        if min_quality:
            total_query = total_query.filter(ContentModel.quality_score >= min_quality)
        
        total = total_query.count()
        
        return ContentListResponse(
            contents=contents,
            total=total,
            filters_applied={
                "content_type": content_type.value if content_type else None,
                "category_id": category_id,
                "min_quality": min_quality
            }
        )
        
    except Exception as e:
        app_logger.error(f"ì½˜í…ì¸  ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ì½˜í…ì¸  ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@router.get("/{content_id}", response_model=GeneratedContent)
async def get_content(content_id: str, db: Session = Depends(get_db)):
    """íŠ¹ì • ì½˜í…ì¸  ì¡°íšŒ"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì½˜í…ì¸  ì¡°íšŒ
        db_content = db.query(ContentModel).filter(ContentModel.id == content_id).first()
        
        if not db_content:
            raise HTTPException(status_code=404, detail="ì½˜í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # GeneratedContent ê°ì²´ë¡œ ë³€í™˜
        metadata = json.loads(db_content.content_metadata) if db_content.content_metadata else {}
        
        return GeneratedContent(
            id=db_content.id,
            topic=db_content.topic,
            category_id=db_content.category_id,
            content_type=db_content.content_type,
            content=db_content.content,
            metadata=metadata,
            quality_score=db_content.quality_score,
            thinking_process=db_content.thinking_process,
            created_at=db_content.created_at.isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"ì½˜í…ì¸  ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ì½˜í…ì¸  ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@router.post("/batch/generate")
async def batch_generate_content(
    request: BatchContentRequest,
    background_tasks: BackgroundTasks,
    thinking_engine: NativeThinkingEngine = Depends(get_thinking_engine),
    generators: Dict[ContentType, Any] = Depends(get_content_generators),
    db: Session = Depends(get_db)
):
    """ë°°ì¹˜ ì½˜í…ì¸  ìƒì„±"""
    try:
        batch_id = f"batch_{datetime.now().strftime('%Y%m%d%H%M%S')}"
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìœ¼ë¡œ ì²˜ë¦¬
        background_tasks.add_task(
            process_batch_generation,
            batch_id,
            request.requests,
            thinking_engine,
            generators,
            db
        )
        
        return {
            "batch_id": batch_id,
            "status": "processing",
            "request_count": len(request.requests),
            "message": "ë°°ì¹˜ ì½˜í…ì¸  ìƒì„±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
        
    except Exception as e:
        app_logger.error(f"ë°°ì¹˜ ì½˜í…ì¸  ìƒì„± ì‹œì‘ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ë°°ì¹˜ ì½˜í…ì¸  ìƒì„± ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

async def process_batch_generation(
    batch_id: str,
    requests: List[ContentRequest],
    thinking_engine: NativeThinkingEngine,
    generators: Dict[ContentType, Any],
    db: Session = None
):
    """ë°°ì¹˜ ìƒì„± ì²˜ë¦¬ (ë°±ê·¸ë¼ìš´ë“œ)"""
    try:
        results = []
        
        for req in requests:
            try:
                # ê° ìš”ì²­ ì²˜ë¦¬
                result = await generate_content(
                    req,
                    thinking_engine,
                    generators
                )
                results.append({
                    "status": "success",
                    "content_id": result.content.id,
                    "topic": req.topic
                })
            except Exception as e:
                results.append({
                    "status": "failed",
                    "topic": req.topic,
                    "error": str(e)
                })
        
        # ê²°ê³¼ ìºì‹œì— ì €ì¥
        advanced_cache.set(
            f"batch_{batch_id}",
            {
                "batch_id": batch_id,
                "status": "completed",
                "results": results,
                "completed_at": datetime.now().isoformat()
            },
            ttl=3600*24  # 24ì‹œê°„
        )
        
        app_logger.info(f"ë°°ì¹˜ ìƒì„± ì™„ë£Œ: {batch_id}")
        
    except Exception as e:
        app_logger.error(f"ë°°ì¹˜ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        
        # ì‹¤íŒ¨ ìƒíƒœ ì €ì¥
        advanced_cache.set(
            f"batch_{batch_id}",
            {
                "batch_id": batch_id,
                "status": "failed",
                "error": str(e),
                "failed_at": datetime.now().isoformat()
            },
            ttl=3600*24
        )

@router.get("/batch/{batch_id}")
async def get_batch_status(batch_id: str):
    """ë°°ì¹˜ ìƒì„± ìƒíƒœ ì¡°íšŒ"""
    try:
        result = advanced_cache.get(f"batch_{batch_id}")
        
        if not result:
            raise HTTPException(status_code=404, detail="ë°°ì¹˜ ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"ë°°ì¹˜ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ë°°ì¹˜ ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@router.post("/regenerate/{content_id}")
async def regenerate_content(
    content_id: str,
    thinking_mode: ThinkingMode = ThinkingMode.ENHANCED,
    thinking_engine: NativeThinkingEngine = Depends(get_thinking_engine),
    generators: Dict[ContentType, Any] = Depends(get_content_generators),
    db: Session = Depends(get_db)
):
    """ì½˜í…ì¸  ì¬ìƒì„±"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ì¡´ ì½˜í…ì¸  ì¡°íšŒ
        db_content = db.query(ContentModel).filter(ContentModel.id == content_id).first()
        
        if not db_content:
            raise HTTPException(status_code=404, detail="ì›ë³¸ ì½˜í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # GeneratedContent ê°ì²´ë¡œ ë³€í™˜
        metadata = json.loads(db_content.content_metadata) if db_content.content_metadata else {}
        existing_content = GeneratedContent(
            id=db_content.id,
            topic=db_content.topic,
            category_id=db_content.category_id,
            content_type=db_content.content_type,
            content=db_content.content,
            metadata=metadata,
            quality_score=db_content.quality_score,
            thinking_process=db_content.thinking_process,
            created_at=db_content.created_at.isoformat()
        )
        
        # ì¬ìƒì„± ìš”ì²­ ìƒì„±
        paper_ids = [db_content.paper_id] if db_content.paper_id else ["paper_001"]
        request = ContentRequest(
            topic=existing_content.topic,
            category_id=existing_content.category_id,
            content_type=existing_content.content_type,
            paper_ids=paper_ids,
            thinking_mode=thinking_mode
        )
        
        # ì½˜í…ì¸  ì¬ìƒì„±
        result = await generate_content(request, thinking_engine, generators, db)
        
        return {
            "status": "success",
            "original_id": content_id,
            "new_id": result.content.id,
            "message": "ì½˜í…ì¸ ê°€ ì„±ê³µì ìœ¼ë¡œ ì¬ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"ì½˜í…ì¸  ì¬ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ì½˜í…ì¸  ì¬ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@router.post("/transform", response_model=ContentResponse)
async def transform_content(
    request: ContentTransformRequest,
    db: Session = Depends(get_db)
):
    """ê¸°ì¡´ ì½˜í…ì¸ ë¥¼ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜"""
    try:
        # ê¸°ì¡´ ì½˜í…ì¸  ì¡°íšŒ
        db_content = db.query(ContentModel).filter(ContentModel.id == request.content_id).first()
        if not db_content:
            raise HTTPException(status_code=404, detail="ì½˜í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        from ..services.gemini_client import GeminiClient
        gemini_client = GeminiClient()
        
        # ë³€í™˜ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        transformation_prompts = {
            TransformationType.HUMANIZE: """
ì•„ë˜ ì½˜í…ì¸ ë¥¼ ì‚¬ëŒì´ ì§ì ‘ ì“´ ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í™˜í•´ì£¼ì„¸ìš”.

[AI ìŠ¤íƒ€ì¼ ì œê±°]
- ë²ˆí˜¸ë¡œ ì‹œì‘í•˜ëŠ” ì„¹ì…˜ ì œê±° (1., 2., 3. â†’ ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ìœ¼ë¡œ)
- ì´ëª¨ì§€ ìµœì†Œí™” (ì „ì²´ ê¸€ì—ì„œ 2-3ê°œë§Œ ì‚¬ìš©)
- ë°˜ë³µì ì¸ ì „í™˜ ë¬¸êµ¬ ë³€ê²½ ("ë‹¤ìŒìœ¼ë¡œ", "ë˜í•œ", "ë§ˆì§€ë§‰ìœ¼ë¡œ" â†’ ë‹¤ì–‘í•œ í‘œí˜„)
- ê³¼ë„í•œ HTML ë°•ìŠ¤ ì œê±° (ì¤‘ìš”í•œ ê²ƒ 1-2ê°œë§Œ ë‚¨ê¸°ê¸°)

[ì‚¬ëŒë‹¤ìš´ í‘œí˜„ ì¶”ê°€]
- ë¶ˆì™„ì „í•œ ë¬¸ì¥ ì‚¬ìš©: "ê·¸ëŸ°ë° ë§ì´ì£ ...", "ì•„, ê·¸ë¦¬ê³ ..."
- ê°œì¸ì  ê²½í—˜ ì•”ì‹œ: "ì œê°€ í•´ë´¤ëŠ”ë°", "ë§ì€ ë¶„ë“¤ì´ ê·¸ëŸ¬ì‹œë”ë¼ê³ ìš”"
- ê°ì • í‘œí˜„: "ì •ë§ ì‹ ê¸°í•˜ì£ ?", "ì´ê±° ì§„ì§œ ì¤‘ìš”í•´ìš”"
- êµ¬ì–´ì²´ í™œìš©: "~í–ˆì–´ìš”", "~ë”ë¼ê³ ìš”", "~ê±°ë“ ìš”"
- ìì—°ìŠ¤ëŸ¬ìš´ ì‹¤ìˆ˜: ê°™ì€ ë‹¨ì–´ ë°˜ë³µ, ë¬¸ì¥ ì¤‘ê°„ì— ìƒê° ì¶”ê°€

[í˜•ì‹ ë³€í™˜]
- ë”±ë”±í•œ ì œëª© â†’ ì§ˆë¬¸ì´ë‚˜ ëŒ€í™”í˜• ì œëª©
- ì •í˜•í™”ëœ êµ¬ì¡° â†’ ì´ì•¼ê¸° íë¦„ìœ¼ë¡œ ì „ê°œ
- ì™„ë²½í•œ ë¬¸ë²• â†’ ì¼ìƒ ëŒ€í™”ì²´
- HTML í˜•ì‹ì€ ìµœì†Œí•œìœ¼ë¡œ ìœ ì§€
""",
            TransformationType.SIMPLIFY: """
ì•„ë˜ ì½˜í…ì¸ ë¥¼ ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë³€í™˜í•´ì£¼ì„¸ìš”.
- ì „ë¬¸ ìš©ì–´ë¥¼ ì¼ìƒì ì¸ í‘œí˜„ìœ¼ë¡œ ë°”ê¾¸ê¸°
- ë³µì¡í•œ ê°œë…ì„ ì¹œìˆ™í•œ ì˜ˆì‹œë¡œ ì„¤ëª…
- ê¸´ ë¬¸ì¥ì„ ì§§ê³  ëª…í™•í•˜ê²Œ ë‚˜ëˆ„ê¸°
- ì¤‘í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ìœ¼ë¡œ ì‘ì„±
- HTML í˜•ì‹ì€ ìœ ì§€í•˜ë˜ ë‚´ìš©ë§Œ ë³€í™˜
""",
            TransformationType.PRACTICAL: """
ì•„ë˜ ì½˜í…ì¸ ë¥¼ ì‹¤ìš©ì ì´ê³  í–‰ë™ ì¤‘ì‹¬ì ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.
- ì´ë¡ ë³´ë‹¤ëŠ” ì‹¤ì œ ì ìš© ë°©ë²• ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…
- êµ¬ì²´ì ì¸ ì‹¤í–‰ ë‹¨ê³„ì™€ íŒ ì œê³µ
- "ì–´ë–»ê²Œ" í•  ìˆ˜ ìˆëŠ”ì§€ì— ì´ˆì 
- ì¦‰ì‹œ ì‹œë„í•´ë³¼ ìˆ˜ ìˆëŠ” ì‹¤ì²œ ë°©ì•ˆ í¬í•¨
- HTML í˜•ì‹ì€ ìœ ì§€í•˜ë˜ ë‚´ìš©ë§Œ ë³€í™˜
""",
            TransformationType.NATURAL_FORMAT: """
ì•„ë˜ ì½˜í…ì¸ ì˜ ì„œì‹ë§Œ ì‚¬ëŒì´ ì“´ ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ë³€í™˜í•´ì£¼ì„¸ìš”.
ê¸€ ê¸¸ì´ëŠ” ìœ ì§€í•˜ë˜ ë‹¤ìŒ ì‚¬í•­ë“¤ì„ ì ìš©:

[ì„œì‹ ë³€í™˜ ê·œì¹™]
- ë”±ë”±í•œ êµ¬ì¡° ì œê±°: ë²ˆí˜¸ ë§¤ê¸°ê¸° ëŒ€ì‹  ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ìœ¼ë¡œ
- ì´ëª¨ì§€ ìµœì†Œí™”: ì „ì²´ ê¸€ì—ì„œ 1-2ê°œë§Œ, ì—†ì–´ë„ ë¬´ë°©
- HTML ë°•ìŠ¤ ì¤„ì´ê¸°: ì •ë§ ì¤‘ìš”í•œ ë¶€ë¶„ 1-2ê°œë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” í‰ë¬¸ìœ¼ë¡œ
- ì„¹ì…˜ ì œëª© ë³€í™”: "1. ì´ê²Œ ë­”ê°€ìš”?" â†’ "ë¨¼ì € ì´ê²Œ ë­”ì§€ë¶€í„° ì•Œì•„ë³¼ê²Œìš”"
- ì „í™˜ ë¬¸êµ¬ ë‹¤ì–‘í™”: ë§¤ë²ˆ ë‹¤ë¥¸ ì—°ê²°ì–´ ì‚¬ìš©
- ë¶ˆì™„ì „í•œ ë¬¸ì¥ í—ˆìš©: "ê·¸ëŸ°ë° ë§ì´ì£ ..." ê°™ì€ êµ¬ì–´ì²´
- ê°œì¸ì  í‘œí˜„ ì¶”ê°€: "ì œê°€ í•´ë´¤ëŠ”ë°", "ê²½í—˜ìƒ", "ë§ì€ ë¶„ë“¤ì´"

[ì œê±°í•  íŒ¨í„´]
- ëª¨ë“  ì„¹ì…˜ì— ì´ëª¨ì§€ ì‚¬ìš©í•˜ëŠ” ê²ƒ
- "ì²«ì§¸, ë‘˜ì§¸, ì…‹ì§¸" ê°™ì€ ìˆœì„œ í‘œí˜„
- ê³¼ë„í•œ <div> ë°•ìŠ¤ë“¤
- "ë‹¤ìŒìœ¼ë¡œ", "ë˜í•œ", "ë§ˆì§€ë§‰ìœ¼ë¡œ" ê°™ì€ í‹€ì— ë°•íŒ ì „í™˜ì–´
- ë„ˆë¬´ ì •í˜•í™”ëœ ì¸ì‚¬ë§

[ìœ ì§€í•  ê²ƒ]
- ì „ì²´ ë‚´ìš©ì˜ ê¸¸ì´ì™€ ì •ë³´ëŸ‰
- í•µì‹¬ ë©”ì‹œì§€ì™€ ë…¼ë¬¸ ì°¸ì¡° ì •ë³´
- ê¸°ë³¸ì ì¸ ê°€ë…ì„± (ë‹¨ë½ êµ¬ë¶„ì€ ìœ ì§€)
- ì¤‘ìš”í•œ ì •ë³´ì˜ ê°•ì¡° (êµµì€ ê¸€ì”¨ ì •ë„ë¡œë§Œ)

[ì˜ˆì‹œ]
ê¸°ì¡´: "ğŸ¯ 1. ì´ê²Œ ë­”ê°€ìš”? - ì˜¤ëŠ˜ì˜ ì£¼ì œë¥¼ ì‰½ê²Œ ì†Œê°œ"
ë³€í™˜: "ë¨¼ì € ì´ê²Œ ë­”ì§€ë¶€í„° ì–˜ê¸°í•´ë³¼ê²Œìš”"

ê¸°ì¡´: <div style="background-color: #e3f2fd; ...">ğŸ’¡ íŒ: ë‚´ìš©</div>
ë³€í™˜: ê·¸ëƒ¥ **ì¤‘ìš”:** ë‚´ìš© (ë˜ëŠ” í‰ë¬¸ìœ¼ë¡œ)
"""
        }
        
        # ë³€í™˜ ì‹¤í–‰
        prompt = f"{transformation_prompts[request.transformation_type]}\n\nì›ë³¸ ì½˜í…ì¸ :\n{db_content.content}"
        
        transformed_content = gemini_client.transform_content(
            content=db_content.content,
            transformation_type=request.transformation_type,
            prompt=prompt
        )
        
        # ìƒˆë¡œìš´ ì½˜í…ì¸  ID ìƒì„±
        new_content_id = f"cnt_transformed_{datetime.now().strftime('%Y%m%d%H%M%S')}_{hash(request.content_id) % 10000}"
        
        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        metadata = json.loads(db_content.content_metadata) if db_content.content_metadata else {}
        metadata['transformation_type'] = request.transformation_type.value
        metadata['original_content_id'] = request.content_id
        metadata['transformed_at'] = datetime.now().isoformat()
        metadata['is_transformed'] = True
        
        # ë³€í™˜ëœ ì½˜í…ì¸  ì €ì¥
        db_transformed = ContentModel(
            id=new_content_id,
            topic=f"{db_content.topic} ({request.transformation_type.value})",
            category_id=db_content.category_id,
            paper_id=db_content.paper_id,
            content_type=db_content.content_type,
            content=transformed_content,
            content_metadata=json.dumps(metadata),
            thinking_process=db_content.thinking_process,
            quality_score=db_content.quality_score
        )
        
        db.add(db_transformed)
        db.commit()
        db.refresh(db_transformed)
        
        # ì‘ë‹µ ìƒì„±
        return ContentResponse(
            content=GeneratedContent(
                id=db_transformed.id,
                topic=db_transformed.topic,
                category_id=db_transformed.category_id,
                content_type=db_transformed.content_type,
                content=db_transformed.content,
                metadata=metadata,
                quality_score=db_transformed.quality_score,
                thinking_process=db_transformed.thinking_process,
                created_at=db_transformed.created_at.isoformat()
            ),
            generation_time=0.0,
            cache_hit=False
        )
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"ì½˜í…ì¸  ë³€í™˜ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ì½˜í…ì¸  ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@router.get("/transformations/{content_id}")
async def get_content_transformations(
    content_id: str,
    db: Session = Depends(get_db)
):
    """íŠ¹ì • ì½˜í…ì¸ ì˜ ëª¨ë“  ë³€í™˜ ë²„ì „ ì¡°íšŒ"""
    try:
        # ì›ë³¸ ì½˜í…ì¸  ì¡°íšŒ
        original = db.query(ContentModel).filter(ContentModel.id == content_id).first()
        if not original:
            raise HTTPException(status_code=404, detail="ì½˜í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì´ ì½˜í…ì¸ ì˜ ëª¨ë“  ë³€í™˜ ë²„ì „ ì°¾ê¸°
        transformations = []
        
        # 1. ì´ ì½˜í…ì¸ ê°€ ì›ë³¸ì¸ ê²½ìš°, ë³€í™˜ëœ ë²„ì „ë“¤ ì°¾ê¸°
        transformed_contents = db.query(ContentModel).filter(
            ContentModel.content_metadata.contains(f'"original_content_id": "{content_id}"')
        ).all()
        
        # 2. ì´ ì½˜í…ì¸ ê°€ ë³€í™˜ëœ ê²ƒì¸ ê²½ìš°, ì›ë³¸ ì°¾ê¸°
        metadata = json.loads(original.content_metadata) if original.content_metadata else {}
        original_id = metadata.get('original_content_id')
        
        if original_id:
            # ì›ë³¸ ì°¾ê¸°
            original_content = db.query(ContentModel).filter(ContentModel.id == original_id).first()
            if original_content:
                transformations.append({
                    "id": original_content.id,
                    "topic": original_content.topic,
                    "transformation_type": "original",
                    "created_at": original_content.created_at.isoformat(),
                    "is_current": False
                })
            
            # ê°™ì€ ì›ë³¸ì„ ê°€ì§„ ë‹¤ë¥¸ ë³€í™˜ë“¤ ì°¾ê¸°
            other_transformations = db.query(ContentModel).filter(
                ContentModel.content_metadata.contains(f'"original_content_id": "{original_id}"'),
                ContentModel.id != content_id
            ).all()
            
            for trans in other_transformations:
                trans_metadata = json.loads(trans.content_metadata) if trans.content_metadata else {}
                transformations.append({
                    "id": trans.id,
                    "topic": trans.topic,
                    "transformation_type": trans_metadata.get('transformation_type', 'unknown'),
                    "created_at": trans.created_at.isoformat(),
                    "is_current": False
                })
        else:
            # í˜„ì¬ ì½˜í…ì¸ ê°€ ì›ë³¸
            transformations.append({
                "id": original.id,
                "topic": original.topic,
                "transformation_type": "original",
                "created_at": original.created_at.isoformat(),
                "is_current": True
            })
        
        # ë³€í™˜ëœ ë²„ì „ë“¤ ì¶”ê°€
        for trans in transformed_contents:
            trans_metadata = json.loads(trans.content_metadata) if trans.content_metadata else {}
            transformations.append({
                "id": trans.id,
                "topic": trans.topic,
                "transformation_type": trans_metadata.get('transformation_type', 'unknown'),
                "created_at": trans.created_at.isoformat(),
                "is_current": trans.id == content_id
            })
        
        # í˜„ì¬ ì½˜í…ì¸  í‘œì‹œ
        current_metadata = json.loads(original.content_metadata) if original.content_metadata else {}
        if current_metadata.get('is_transformed'):
            current_type = current_metadata.get('transformation_type', 'unknown')
        else:
            current_type = 'original'
        
        # ì‹œê°„ìˆœ ì •ë ¬
        transformations.sort(key=lambda x: x['created_at'])
        
        # í˜„ì¬ ì½˜í…ì¸  í‘œì‹œ ì—…ë°ì´íŠ¸
        for trans in transformations:
            if trans['id'] == content_id:
                trans['is_current'] = True
        
        return {
            "current_content_id": content_id,
            "current_type": current_type,
            "transformations": transformations,
            "total": len(transformations)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"ë³€í™˜ ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ë³€í™˜ ì´ë ¥ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@router.get("/workflow/summary")
async def get_workflow_summary():
    """í˜„ì¬ ì›Œí¬í”Œë¡œìš°ì˜ í† í° ì‚¬ìš©ëŸ‰ ë° ë¹„ìš© ìš”ì•½ ì¡°íšŒ"""
    try:
        summary = token_tracker.get_session_summary()
        
        # USD ê³„ì‚°
        cost_usd = token_tracker._calculate_cost_usd(
            summary['total_prompt_tokens'], 
            summary['total_response_tokens']
        )
        
        return {
            "total_operations": summary['operation_count'],
            "total_tokens": summary['total_tokens'],
            "prompt_tokens": summary['total_prompt_tokens'],
            "response_tokens": summary['total_response_tokens'],
            "estimated_cost_usd": round(cost_usd, 4),
            "estimated_cost_krw": round(summary['estimated_cost_krw'], 2),
            "session_duration": summary['session_duration'],
            "operations_breakdown": summary['operations']
        }
        
    except Exception as e:
        app_logger.error(f"ì›Œí¬í”Œë¡œìš° ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì›Œí¬í”Œë¡œìš° ìš”ì•½ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@router.post("/workflow/complete")
async def complete_workflow(
    workflow_name: str = Query(..., description="ì›Œí¬í”Œë¡œìš° ì´ë¦„"),
    reset_after: bool = Query(True, description="ìš”ì•½ í›„ í† í° ì¶”ì ê¸° ë¦¬ì…‹ ì—¬ë¶€")
):
    """ì „ì²´ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì‹œ í† í° ì‚¬ìš©ëŸ‰ ì´í•© ë¡œê¹…"""
    try:
        # ì „ì²´ ì›Œí¬í”Œë¡œìš° ìš”ì•½ ë¡œê¹…
        token_tracker.log_workflow_summary(f"Complete Workflow: {workflow_name}")
        
        # í† í° ì¶”ì ê¸° ë¦¬ì…‹ (ì„ íƒì )
        if reset_after:
            token_tracker.reset()
        
        return {"message": "ì›Œí¬í”Œë¡œìš° í† í° ì‚¬ìš©ëŸ‰ ìš”ì•½ì´ ë¡œê·¸ì— ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤."}
    
    except Exception as e:
        app_logger.error(f"ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì›Œí¬í”Œë¡œìš° ì™„ë£Œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@router.delete("/{content_id}")
async def delete_content(content_id: str, db: Session = Depends(get_db)):
    """ì½˜í…ì¸  ì‚­ì œ"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì½˜í…ì¸  ì¡°íšŒ
        db_content = db.query(ContentModel).filter(ContentModel.id == content_id).first()
        
        if not db_content:
            raise HTTPException(status_code=404, detail="ì½˜í…ì¸ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì½˜í…ì¸  ì‚­ì œ
        db.delete(db_content)
        db.commit()
        
        # ìºì‹œì—ì„œë„ ì‚­ì œ
        cache_key = f"content_{hash(str({'topic': db_content.topic, 'category_id': db_content.category_id, 'content_type': db_content.content_type}))}"
        advanced_cache.delete(cache_key)
        
        app_logger.info(f"ì½˜í…ì¸  ì‚­ì œ ì™„ë£Œ: {content_id}")
        
        # ê°ì‚¬ ë¡œê¹…
        audit_logger.log_action(
            action="delete_content",
            entity_type="content",
            entity_id=content_id,
            changes={
                "topic": db_content.topic,
                "type": db_content.content_type
            }
        )
        
        return {"message": "ì½˜í…ì¸ ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤", "id": content_id}
            
    except HTTPException:
        raise
    except Exception as e:
        app_logger.error(f"ì½˜í…ì¸  ì‚­ì œ ì‹¤íŒ¨: {e}", exc_info=True)
        db.rollback()
        raise HTTPException(status_code=500, detail="ì½˜í…ì¸  ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")