"""
ë² ì´ìŠ¤ ì½˜í…ì¸  ìƒì„±ê¸° - ëª¨ë“  ì½˜í…ì¸  í˜•ì‹ì˜ ê¸°ë³¸ í´ë˜ìŠ¤
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import re
import time

@dataclass
class ContentSection:
    """ì½˜í…ì¸  ì„¹ì…˜"""
    title: str
    content: str
    duration: Optional[int] = None  # ì´ˆ ë‹¨ìœ„ (ìˆì¸ ìš©)
    word_count: Optional[int] = None  # ê¸€ììˆ˜ (ì•„í‹°í´ìš©)

@dataclass
class GeneratedContent:
    """ìƒì„±ëœ ì½˜í…ì¸ """
    content_type: str
    title: str
    sections: List[ContentSection]
    total_content: str
    metadata: Dict[str, Any]
    thinking_process: str
    generation_time: float
    quality_score: float

class BaseContentGenerator(ABC):
    """ì½˜í…ì¸  ìƒì„±ê¸° ë² ì´ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.content_type = "base"
        self.thinking_markers = ["<thinking>", "</thinking>"]
        
    @abstractmethod
    def generate(self, topic: str, papers: List[Any], **kwargs) -> GeneratedContent:
        """ì½˜í…ì¸  ìƒì„± - ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„"""
        pass
    
    @abstractmethod
    def create_prompt(self, topic: str, papers: List[Any], **kwargs) -> str:
        """í”„ë¡¬í”„íŠ¸ ìƒì„± - ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„"""
        pass
    
    @abstractmethod
    def parse_response(self, response: str) -> Dict[str, Any]:
        """ì‘ë‹µ íŒŒì‹± - ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„"""
        pass
    
    def extract_thinking_process(self, response: str) -> tuple[str, str]:
        """ì‚¬ê³  ê³¼ì • ì¶”ì¶œ"""
        thinking_pattern = r'<thinking>(.*?)</thinking>'
        thinking_matches = re.findall(thinking_pattern, response, re.DOTALL)
        
        if thinking_matches:
            thinking_process = '\n'.join(thinking_matches)
            # ì‚¬ê³  ê³¼ì • ì œê±°í•œ ì½˜í…ì¸ 
            clean_content = re.sub(thinking_pattern, '', response, flags=re.DOTALL)
            return thinking_process.strip(), clean_content.strip()
        
        return "", response
    
    def calculate_quality_score(self, content: str, papers: List[Any]) -> float:
        """ì½˜í…ì¸  í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        
        # 1. ë…¼ë¬¸ ì¸ìš© í™•ì¸ (30ì )
        paper_citations = sum(1 for paper in papers if any(
            keyword in content.lower() 
            for keyword in [paper.title.lower()[:20], paper.authors.split()[0].lower()]
        ))
        score += min(paper_citations * 10, 30)
        
        # 2. êµ¬ì¡°í™” ìˆ˜ì¤€ (20ì )
        structure_keywords = ['ì²«ì§¸', 'ë‘˜ì§¸', '1.', '2.', 'ë‹¨ê³„', 'ë°©ë²•', 'íŒ', 'ê²°ë¡ ']
        structure_count = sum(1 for keyword in structure_keywords if keyword in content)
        score += min(structure_count * 5, 20)
        
        # 3. ì‹¤ìš©ì„± í‚¤ì›Œë“œ (20ì )
        practical_keywords = ['í•˜ëŠ”ë²•', 'ë°©ë²•', 'ê¿€íŒ', 'ì£¼ì˜ì‚¬í•­', 'ì¶”ì²œ', 'ê°€ì´ë“œ']
        practical_count = sum(1 for keyword in practical_keywords if keyword in content)
        score += min(practical_count * 5, 20)
        
        # 4. ì ì ˆí•œ ê¸¸ì´ (15ì )
        if self.content_type == "shorts":
            ideal_length = 300  # 45-60ì´ˆ ë¶„ëŸ‰
            length_ratio = min(len(content) / ideal_length, ideal_length / len(content))
            score += length_ratio * 15
        elif self.content_type == "article":
            ideal_length = 2500  # 2000-3000ì
            if 2000 <= len(content) <= 3000:
                score += 15
            else:
                score += max(0, 15 - abs(len(content) - ideal_length) / 100)
        
        # 5. ê°€ë…ì„± (15ì )
        sentences = content.split('.')
        avg_sentence_length = sum(len(s) for s in sentences) / max(len(sentences), 1)
        if 20 <= avg_sentence_length <= 40:  # ì´ìƒì ì¸ ë¬¸ì¥ ê¸¸ì´
            score += 15
        else:
            score += max(0, 15 - abs(avg_sentence_length - 30) / 2)
        
        return min(score, 100)
    
    def format_paper_info(self, papers: List[Any]) -> str:
        """ë…¼ë¬¸ ì •ë³´ í¬ë§·íŒ…"""
        paper_info = []
        for i, paper in enumerate(papers, 1):
            info = f"{i}. {paper.title}\n"
            info += f"   - ì €ì: {paper.authors}\n"
            info += f"   - ì €ë„: {paper.journal} ({paper.year})\n"
            info += f"   - ì£¼ìš” ë°œê²¬: {getattr(paper, 'key_findings', 'N/A')}"
            paper_info.append(info)
        
        return "\n\n".join(paper_info)
    
    def apply_tone_and_style(self, content: str, target_audience: str = "general") -> str:
        """íƒ€ê²Ÿ ì²­ì¤‘ì— ë§ëŠ” í†¤ì•¤ë§¤ë„ˆ ì ìš©"""
        tone_adjustments = {
            "general": {
                "replacements": [
                    ("ì—°êµ¬ì— ë”°ë¥´ë©´", "ìµœì‹  ì—°êµ¬ì—ì„œ ë°í˜€ì§„ ë°”ë¡œëŠ”"),
                    ("ê²°ê³¼ì ìœ¼ë¡œ", "ê·¸ ê²°ê³¼"),
                    ("ë”°ë¼ì„œ", "ê·¸ë˜ì„œ")
                ],
                "prefix": "",
                "suffix": ""
            },
            "beginner": {
                "replacements": [
                    ("ìœ ì‚°ì†Œ ìš´ë™", "ì‹¬ì¥ì„ ë›°ê²Œ í•˜ëŠ” ìš´ë™"),
                    ("ê·¼ë ¥ ìš´ë™", "ê·¼ìœ¡ì„ í‚¤ìš°ëŠ” ìš´ë™"),
                    ("ëŒ€ì‚¬ìœ¨", "ì¹¼ë¡œë¦¬ ì†Œëª¨ ì†ë„")
                ],
                "prefix": "ğŸ’¡ ì´ˆë³´ìë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì„¤ëª…ë“œë¦´ê²Œìš”!\n\n",
                "suffix": "\n\nğŸ¯ ì²œì²œíˆ ë”°ë¼í•´ë³´ì„¸ìš”!"
            },
            "expert": {
                "replacements": [
                    ("íš¨ê³¼ê°€ ìˆë‹¤", "í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ íš¨ê³¼ê°€ ê´€ì°°ë˜ì—ˆë‹¤"),
                    ("ì¦ê°€í–ˆë‹¤", "ìœ ì˜ë¯¸í•œ ì¦ê°€ë¥¼ ë³´ì˜€ë‹¤"),
                    ("ê°ì†Œí–ˆë‹¤", "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ê°ì†Œê°€ ë‚˜íƒ€ë‚¬ë‹¤")
                ],
                "prefix": "ğŸ“Š ì „ë¬¸ê°€ë¥¼ ìœ„í•œ ì‹¬í™” ë¶„ì„\n\n",
                "suffix": "\n\nğŸ“ˆ ì¶”ê°€ ì—°êµ¬ ìë£ŒëŠ” ì°¸ê³ ë¬¸í—Œì„ í™•ì¸í•˜ì„¸ìš”."
            }
        }
        
        adjustments = tone_adjustments.get(target_audience, tone_adjustments["general"])
        
        # ì¹˜í™˜ ì ìš©
        adjusted_content = content
        for old, new in adjustments["replacements"]:
            adjusted_content = adjusted_content.replace(old, new)
        
        # ì ‘ë‘ì‚¬/ì ‘ë¯¸ì‚¬ ì¶”ê°€
        return adjustments["prefix"] + adjusted_content + adjustments["suffix"]