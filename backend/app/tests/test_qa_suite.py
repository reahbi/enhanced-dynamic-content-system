"""
QA í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ - í¬ê´„ì ì¸ í’ˆì§ˆ ë³´ì¦ í…ŒìŠ¤íŠ¸
"""

import pytest
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
import os
from pathlib import Path

from ..services.category_optimizer import CategoryOptimizer
from ..services.paper_quality_evaluator import PaperQualityEvaluator
from ..services.content_generators.shorts_generator import ShortsScriptGenerator
from ..services.content_generators.article_generator import ArticleGenerator
from ..services.content_generators.report_generator import ReportGenerator
from ..services.thinking.thinking_integration import ThinkingEnabledContentGenerator
from ..services.thinking.prompt_engineering import ContentType
from ..services.advanced_cache_manager import AdvancedCacheManager
from ..services.performance_optimizer import PerformanceOptimizer
from ..services.system_monitor import SystemMonitor

class QATestSuite:
    """QA í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸"""
    
    def __init__(self):
        self.test_results = []
        self.error_log = []
        self.performance_metrics = []
        
    async def run_all_qa_tests(self):
        """ëª¨ë“  QA í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸ§ª QA í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹œì‘...")
        print("=" * 80)
        
        # í…ŒìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬ë³„ ì‹¤í–‰
        test_categories = [
            ("ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸", self._run_functional_tests),
            ("ì„±ëŠ¥ í…ŒìŠ¤íŠ¸", self._run_performance_tests),
            ("ì‹ ë¢°ì„± í…ŒìŠ¤íŠ¸", self._run_reliability_tests),
            ("ë³´ì•ˆ í…ŒìŠ¤íŠ¸", self._run_security_tests),
            ("ì‚¬ìš©ì„± í…ŒìŠ¤íŠ¸", self._run_usability_tests),
            ("í†µí•© í…ŒìŠ¤íŠ¸", self._run_integration_tests),
            ("ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸", self._run_edge_case_tests)
        ]
        
        for category_name, test_func in test_categories:
            print(f"\nğŸ“ {category_name}")
            print("-" * 60)
            await test_func()
            
        # ê²°ê³¼ ìš”ì•½ ë° ë¦¬í¬íŠ¸ ìƒì„±
        self._generate_qa_report()
        
    async def _run_functional_tests(self):
        """ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        tests = [
            self._test_category_generation,
            self._test_paper_evaluation,
            self._test_content_generation,
            self._test_thinking_mode,
            self._test_caching_functionality
        ]
        
        for test in tests:
            await self._execute_test(test)
            
    async def _run_performance_tests(self):
        """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        tests = [
            self._test_response_time,
            self._test_throughput,
            self._test_memory_usage,
            self._test_concurrent_requests,
            self._test_cache_performance
        ]
        
        for test in tests:
            await self._execute_test(test)
            
    async def _run_reliability_tests(self):
        """ì‹ ë¢°ì„± í…ŒìŠ¤íŠ¸"""
        tests = [
            self._test_error_recovery,
            self._test_data_consistency,
            self._test_failure_handling,
            self._test_timeout_handling
        ]
        
        for test in tests:
            await self._execute_test(test)
            
    async def _run_security_tests(self):
        """ë³´ì•ˆ í…ŒìŠ¤íŠ¸"""
        tests = [
            self._test_input_validation,
            self._test_injection_prevention,
            self._test_data_sanitization
        ]
        
        for test in tests:
            await self._execute_test(test)
            
    async def _run_usability_tests(self):
        """ì‚¬ìš©ì„± í…ŒìŠ¤íŠ¸"""
        tests = [
            self._test_api_consistency,
            self._test_error_messages,
            self._test_default_behaviors
        ]
        
        for test in tests:
            await self._execute_test(test)
            
    async def _run_integration_tests(self):
        """í†µí•© í…ŒìŠ¤íŠ¸"""
        tests = [
            self._test_end_to_end_flow,
            self._test_component_interactions,
            self._test_data_flow
        ]
        
        for test in tests:
            await self._execute_test(test)
            
    async def _run_edge_case_tests(self):
        """ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
        tests = [
            self._test_empty_inputs,
            self._test_large_inputs,
            self._test_special_characters,
            self._test_boundary_values
        ]
        
        for test in tests:
            await self._execute_test(test)
            
    async def _execute_test(self, test_func):
        """ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        test_name = test_func.__name__.replace('_test_', '').replace('_', ' ').title()
        
        try:
            start_time = datetime.now()
            result = await test_func()
            end_time = datetime.now()
            
            self.test_results.append({
                'test_name': test_name,
                'status': 'PASS' if result else 'FAIL',
                'execution_time': (end_time - start_time).total_seconds(),
                'timestamp': datetime.now().isoformat()
            })
            
            status_icon = "âœ…" if result else "âŒ"
            print(f"{status_icon} {test_name}")
            
        except Exception as e:
            self.test_results.append({
                'test_name': test_name,
                'status': 'ERROR',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            })
            
            self.error_log.append({
                'test_name': test_name,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            })
            
            print(f"ğŸ’¥ {test_name} - Error: {str(e)[:50]}...")
            
    # ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ êµ¬í˜„
    async def _test_category_generation(self) -> bool:
        """ì¹´í…Œê³ ë¦¬ ìƒì„± í…ŒìŠ¤íŠ¸"""
        optimizer = CategoryOptimizer()
        
        test_cases = [
            "ë³µë¶€ ìš´ë™",
            "ë‹¨ë°±ì§ˆ ì„­ì·¨",
            "HIIT íŠ¸ë ˆì´ë‹",
            ""  # ë¹ˆ ì…ë ¥
        ]
        
        for keyword in test_cases:
            if keyword:  # ì •ìƒ ì¼€ì´ìŠ¤
                categories = await optimizer.generate_categories(keyword)
                if not categories or len(categories) == 0:
                    return False
            else:  # ë¹ˆ ì…ë ¥
                try:
                    categories = await optimizer.generate_categories(keyword)
                    # ë¹ˆ ì…ë ¥ì€ ì—ëŸ¬ë‚˜ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•´ì•¼ í•¨
                    if categories and len(categories) > 0:
                        return False
                except:
                    pass  # ì˜ˆì™¸ ë°œìƒì€ ì •ìƒ
                    
        return True
        
    async def _test_paper_evaluation(self) -> bool:
        """ë…¼ë¬¸ í‰ê°€ í…ŒìŠ¤íŠ¸"""
        evaluator = PaperQualityEvaluator()
        
        # ë‹¤ì–‘í•œ í’ˆì§ˆì˜ ë…¼ë¬¸ í…ŒìŠ¤íŠ¸
        test_papers = [
            MockPaper(impact_factor=15.0, citations=200, paper_type="Systematic Review"),
            MockPaper(impact_factor=2.0, citations=10, paper_type="Case Report"),
            MockPaper(impact_factor=0, citations=0, paper_type="Unknown")
        ]
        
        grades = []
        for paper in test_papers:
            quality_info = evaluator.evaluate_paper(paper)
            grades.append(quality_info.grade.value)
            
        # ë‹¤ì–‘í•œ ë“±ê¸‰ì´ ë‚˜ì™€ì•¼ í•¨
        unique_grades = len(set(grades))
        return unique_grades >= 2
        
    async def _test_content_generation(self) -> bool:
        """ì½˜í…ì¸  ìƒì„± í…ŒìŠ¤íŠ¸"""
        generator = ThinkingEnabledContentGenerator()
        
        papers = [MockPaper(
            title="Test Paper",
            impact_factor=5.0,
            citations=50
        )]
        
        # ê° ì½˜í…ì¸  íƒ€ì… í…ŒìŠ¤íŠ¸
        for content_type in [ContentType.SHORTS, ContentType.ARTICLE, ContentType.REPORT]:
            result = await generator.generate_with_thinking(
                content_type=content_type,
                topic="í…ŒìŠ¤íŠ¸ ì£¼ì œ",
                papers=papers,
                target_audience='general'
            )
            
            if not result or not result.get('content'):
                return False
                
        return True
        
    async def _test_thinking_mode(self) -> bool:
        """Native Thinking Mode í…ŒìŠ¤íŠ¸"""
        generator = ThinkingEnabledContentGenerator()
        
        result = await generator.generate_with_thinking(
            content_type=ContentType.ARTICLE,
            topic="ê·¼ìœ¡ ì„±ì¥",
            papers=[MockPaper()],
            target_audience='general'
        )
        
        # Thinking í”„ë¡œì„¸ìŠ¤ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨
        thinking_data = result.get('thinking', {})
        return (thinking_data.get('quality_score', 0) > 0 and
                thinking_data.get('process', '') != '')
        
    async def _test_caching_functionality(self) -> bool:
        """ìºì‹± ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
        cache = AdvancedCacheManager(cache_dir="./test_cache")
        
        # ì €ì¥ í…ŒìŠ¤íŠ¸
        test_data = {"key": "value", "timestamp": datetime.now().isoformat()}
        cache.set("test_key", test_data, ttl=3600)
        
        # ì¡°íšŒ í…ŒìŠ¤íŠ¸
        retrieved = cache.get("test_key")
        
        # ì‚­ì œ í…ŒìŠ¤íŠ¸
        cache.delete("test_key")
        deleted = cache.get("test_key")
        
        # ì •ë¦¬
        cache.clear()
        
        return retrieved == test_data and deleted is None
        
    # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ êµ¬í˜„
    async def _test_response_time(self) -> bool:
        """ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸"""
        generator = ShortsScriptGenerator()
        
        start = datetime.now()
        result = generator.generate(
            "í…ŒìŠ¤íŠ¸ ì£¼ì œ",
            [MockPaper()],
            target_audience='general'
        )
        end = datetime.now()
        
        response_time = (end - start).total_seconds()
        
        # ìˆì¸  ìƒì„±ì€ 5ì´ˆ ì´ë‚´ì—¬ì•¼ í•¨
        return response_time < 5.0
        
    async def _test_throughput(self) -> bool:
        """ì²˜ë¦¬ëŸ‰ í…ŒìŠ¤íŠ¸"""
        generator = ThinkingEnabledContentGenerator()
        
        # 10ê°œì˜ ìš”ì²­ì„ ë™ì‹œì— ì²˜ë¦¬
        tasks = []
        for i in range(10):
            task = generator.generate_with_thinking(
                content_type=ContentType.SHORTS,
                topic=f"í…ŒìŠ¤íŠ¸ ì£¼ì œ {i}",
                papers=[MockPaper()],
                target_audience='general'
            )
            tasks.append(task)
            
        start = datetime.now()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        end = datetime.now()
        
        total_time = (end - start).total_seconds()
        successful = sum(1 for r in results if not isinstance(r, Exception))
        
        # 10ê°œ ìš”ì²­ì„ 30ì´ˆ ì´ë‚´ì— ì²˜ë¦¬í•˜ê³  80% ì´ìƒ ì„±ê³µí•´ì•¼ í•¨
        return total_time < 30 and successful >= 8
        
    async def _test_memory_usage(self) -> bool:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
        import psutil
        process = psutil.Process()
        
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # ëŒ€ëŸ‰ì˜ ì½˜í…ì¸  ìƒì„±
        generator = ArticleGenerator()
        for i in range(20):
            generator.generate(
                f"í…ŒìŠ¤íŠ¸ ì£¼ì œ {i}",
                [MockPaper() for _ in range(5)],
                target_audience='general'
            )
            
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        # ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ì´ 500MB ë¯¸ë§Œì´ì–´ì•¼ í•¨
        return memory_increase < 500
        
    async def _test_concurrent_requests(self) -> bool:
        """ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        generator = ThinkingEnabledContentGenerator()
        
        # 50ê°œì˜ ë™ì‹œ ìš”ì²­
        concurrent_count = 50
        tasks = []
        
        for i in range(concurrent_count):
            task = generator.generate_with_thinking(
                content_type=ContentType.SHORTS,
                topic=f"ë™ì‹œ ìš”ì²­ {i}",
                papers=[MockPaper()],
                target_audience='general'
            )
            tasks.append(task)
            
        results = await asyncio.gather(*tasks, return_exceptions=True)
        successful = sum(1 for r in results if not isinstance(r, Exception))
        
        # 90% ì´ìƒ ì„±ê³µí•´ì•¼ í•¨
        return successful >= concurrent_count * 0.9
        
    async def _test_cache_performance(self) -> bool:
        """ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        cache = AdvancedCacheManager()
        
        # 1000ê°œ í•­ëª© ì €ì¥
        start = datetime.now()
        for i in range(1000):
            cache.set(f"perf_test_{i}", f"value_{i}", ttl=3600)
        write_time = (datetime.now() - start).total_seconds()
        
        # 1000ê°œ í•­ëª© ì¡°íšŒ
        start = datetime.now()
        for i in range(1000):
            cache.get(f"perf_test_{i}")
        read_time = (datetime.now() - start).total_seconds()
        
        # ì •ë¦¬
        for i in range(1000):
            cache.delete(f"perf_test_{i}")
            
        # ì“°ê¸°ëŠ” 10ì´ˆ, ì½ê¸°ëŠ” 1ì´ˆ ì´ë‚´ì—¬ì•¼ í•¨
        return write_time < 10 and read_time < 1
        
    # ì‹ ë¢°ì„± í…ŒìŠ¤íŠ¸ êµ¬í˜„
    async def _test_error_recovery(self) -> bool:
        """ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸"""
        generator = ThinkingEnabledContentGenerator()
        
        # ì˜ëª»ëœ ì…ë ¥ìœ¼ë¡œ ì—ëŸ¬ ìœ ë°œ
        try:
            result = await generator.generate_with_thinking(
                content_type=ContentType.SHORTS,
                topic="",  # ë¹ˆ ì£¼ì œ
                papers=None,  # None ë…¼ë¬¸
                target_audience='general'
            )
            # ì—ëŸ¬ê°€ ë°œìƒí•˜ê±°ë‚˜ ê¸°ë³¸ê°’ì´ ë°˜í™˜ë˜ì–´ì•¼ í•¨
            return True
        except:
            # ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ì‹œìŠ¤í…œì´ ì¤‘ë‹¨ë˜ì§€ ì•Šìœ¼ë©´ ì„±ê³µ
            return True
            
    async def _test_data_consistency(self) -> bool:
        """ë°ì´í„° ì¼ê´€ì„± í…ŒìŠ¤íŠ¸"""
        cache = AdvancedCacheManager()
        
        # ë™ì¼í•œ í‚¤ì— ì—¬ëŸ¬ ë²ˆ ì €ì¥
        for i in range(10):
            cache.set("consistency_test", f"value_{i}", ttl=3600)
            
        # ìµœì¢… ê°’ í™•ì¸
        final_value = cache.get("consistency_test")
        cache.delete("consistency_test")
        
        return final_value == "value_9"
        
    async def _test_failure_handling(self) -> bool:
        """ì‹¤íŒ¨ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        evaluator = PaperQualityEvaluator()
        
        # ì˜ëª»ëœ ë…¼ë¬¸ ê°ì²´
        invalid_papers = [
            None,
            {},
            "string",
            123
        ]
        
        for paper in invalid_papers:
            try:
                evaluator.evaluate_paper(paper)
            except:
                pass  # ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ì‹œìŠ¤í…œì´ ê³„ì† ë™ì‘í•´ì•¼ í•¨
                
        return True  # í¬ë˜ì‹œí•˜ì§€ ì•Šìœ¼ë©´ ì„±ê³µ
        
    async def _test_timeout_handling(self) -> bool:
        """íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # ì‹œë®¬ë ˆì´ì…˜: ê¸´ ì‘ì—…
        async def long_running_task():
            await asyncio.sleep(10)
            return "completed"
            
        try:
            # 5ì´ˆ íƒ€ì„ì•„ì›ƒ
            result = await asyncio.wait_for(long_running_task(), timeout=5)
            return False  # íƒ€ì„ì•„ì›ƒì´ ë°œìƒí•´ì•¼ í•¨
        except asyncio.TimeoutError:
            return True  # íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ì„±ê³µ
            
    # ë³´ì•ˆ í…ŒìŠ¤íŠ¸ êµ¬í˜„
    async def _test_input_validation(self) -> bool:
        """ì…ë ¥ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        optimizer = CategoryOptimizer()
        
        # ìœ„í—˜í•œ ì…ë ¥ë“¤
        dangerous_inputs = [
            "<script>alert('xss')</script>",
            "'; DROP TABLE users; --",
            "../../../etc/passwd",
            "\\x00\\x01\\x02",
            "A" * 10000  # ë§¤ìš° ê¸´ ì…ë ¥
        ]
        
        for dangerous_input in dangerous_inputs:
            try:
                # ìœ„í—˜í•œ ì…ë ¥ì´ ì²˜ë¦¬ë˜ê±°ë‚˜ ê±°ë¶€ë˜ì–´ì•¼ í•¨
                categories = await optimizer.generate_categories(dangerous_input)
                # ì¹´í…Œê³ ë¦¬ê°€ ìƒì„±ë˜ì—ˆë‹¤ë©´ sanitizationì´ ë˜ì—ˆëŠ”ì§€ í™•ì¸
                for category in categories:
                    if any(char in category.get('name', '') for char in ['<', '>', ';', '--']):
                        return False
            except:
                pass  # ì˜ˆì™¸ ë°œìƒì€ ì •ìƒ
                
        return True
        
    async def _test_injection_prevention(self) -> bool:
        """ì¸ì ì…˜ ë°©ì§€ í…ŒìŠ¤íŠ¸"""
        # SQL ì¸ì ì…˜ ì‹œë„
        malicious_inputs = [
            "1' OR '1'='1",
            "admin'--",
            "1; DELETE FROM papers WHERE 1=1"
        ]
        
        # ìºì‹œ í‚¤ ìƒì„± ì‹œ ì¸ì ì…˜ ë°©ì§€ í™•ì¸
        cache = AdvancedCacheManager()
        for input_str in malicious_inputs:
            key = f"test_{input_str}"
            cache.set(key, "test_value", ttl=60)
            
            # ì €ì¥ëœ í‚¤ê°€ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
            retrieved = cache.get(key)
            cache.delete(key)
            
            if retrieved != "test_value":
                return False
                
        return True
        
    async def _test_data_sanitization(self) -> bool:
        """ë°ì´í„° ì •ì œ í…ŒìŠ¤íŠ¸"""
        generator = ShortsScriptGenerator()
        
        # HTML/ìŠ¤í¬ë¦½íŠ¸ê°€ í¬í•¨ëœ ë…¼ë¬¸
        malicious_paper = MockPaper(
            title="<script>alert('xss')</script> Research",
            authors="'; DROP TABLE users; --"
        )
        
        result = generator.generate(
            "í…ŒìŠ¤íŠ¸ ì£¼ì œ",
            [malicious_paper],
            target_audience='general'
        )
        
        # ìƒì„±ëœ ì½˜í…ì¸ ì— ìœ„í—˜í•œ ì½”ë“œê°€ ì—†ì–´ì•¼ í•¨
        content = result.total_content
        dangerous_patterns = ['<script>', '</script>', 'DROP TABLE', '--']
        
        for pattern in dangerous_patterns:
            if pattern in content:
                return False
                
        return True
        
    # ì‚¬ìš©ì„± í…ŒìŠ¤íŠ¸ êµ¬í˜„
    async def _test_api_consistency(self) -> bool:
        """API ì¼ê´€ì„± í…ŒìŠ¤íŠ¸"""
        # ëª¨ë“  ìƒì„±ê¸°ê°€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤ë¥¼ ê°€ì ¸ì•¼ í•¨
        generators = [
            ShortsScriptGenerator(),
            ArticleGenerator(),
            ReportGenerator()
        ]
        
        for generator in generators:
            # generate ë©”ì„œë“œê°€ ìˆì–´ì•¼ í•¨
            if not hasattr(generator, 'generate'):
                return False
                
            # ë™ì¼í•œ íŒŒë¼ë¯¸í„°ë¥¼ ë°›ì•„ì•¼ í•¨
            result = generator.generate(
                topic="í…ŒìŠ¤íŠ¸",
                papers=[MockPaper()],
                target_audience='general'
            )
            
            # ê²°ê³¼ê°€ GeneratedContent íƒ€ì…ì´ì–´ì•¼ í•¨
            if not hasattr(result, 'total_content'):
                return False
                
        return True
        
    async def _test_error_messages(self) -> bool:
        """ì—ëŸ¬ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸"""
        generator = ThinkingEnabledContentGenerator()
        
        # ì˜ë„ì ì¸ ì—ëŸ¬ ìœ ë°œ
        try:
            await generator.generate_with_thinking(
                content_type="invalid_type",  # ì˜ëª»ëœ íƒ€ì…
                topic="í…ŒìŠ¤íŠ¸",
                papers=[],
                target_audience='general'
            )
            return False  # ì—ëŸ¬ê°€ ë°œìƒí•´ì•¼ í•¨
        except Exception as e:
            # ì—ëŸ¬ ë©”ì‹œì§€ê°€ ëª…í™•í•´ì•¼ í•¨
            error_msg = str(e).lower()
            return 'content type' in error_msg or 'invalid' in error_msg
            
    async def _test_default_behaviors(self) -> bool:
        """ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸"""
        cache = AdvancedCacheManager()
        
        # ê¸°ë³¸ TTL í…ŒìŠ¤íŠ¸
        cache.set("default_test", "value")  # TTL ë¯¸ì§€ì •
        value = cache.get("default_test")
        cache.delete("default_test")
        
        return value == "value"  # ê¸°ë³¸ TTLì´ ì ìš©ë˜ì–´ì•¼ í•¨
        
    # í†µí•© í…ŒìŠ¤íŠ¸ êµ¬í˜„
    async def _test_end_to_end_flow(self) -> bool:
        """ì „ì²´ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        # 1. ì¹´í…Œê³ ë¦¬ ìƒì„±
        optimizer = CategoryOptimizer()
        categories = await optimizer.generate_categories("í™ˆíŠ¸ë ˆì´ë‹")
        
        if not categories:
            return False
            
        # 2. ë…¼ë¬¸ í‰ê°€
        evaluator = PaperQualityEvaluator()
        papers = [MockPaper(impact_factor=8.0, citations=100)]
        quality_info = evaluator.evaluate_paper(papers[0])
        
        # 3. ì½˜í…ì¸  ìƒì„±
        generator = ThinkingEnabledContentGenerator()
        result = await generator.generate_with_thinking(
            content_type=ContentType.ARTICLE,
            topic=categories[0]['name'],
            papers=papers,
            target_audience='general'
        )
        
        # 4. ìºì‹±
        cache = AdvancedCacheManager()
        cache_key = f"e2e_test_{categories[0]['name']}"
        cache.set(cache_key, result, ttl=3600)
        
        # 5. ìºì‹œ ì¡°íšŒ
        cached_result = cache.get(cache_key)
        cache.delete(cache_key)
        
        return cached_result is not None
        
    async def _test_component_interactions(self) -> bool:
        """ì»´í¬ë„ŒíŠ¸ ìƒí˜¸ì‘ìš© í…ŒìŠ¤íŠ¸"""
        # ì—¬ëŸ¬ ì»´í¬ë„ŒíŠ¸ê°€ í•¨ê»˜ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
        monitor = SystemMonitor()
        optimizer = PerformanceOptimizer()
        
        # ëª¨ë‹ˆí„°ë§ ì‹œì‘
        await monitor.start_monitoring()
        
        # ì„±ëŠ¥ ì¸¡ì •ê³¼ í•¨ê»˜ ì‘ì—… ì‹¤í–‰
        @optimizer.measure_performance("test_operation")
        async def test_operation():
            generator = ShortsScriptGenerator()
            return generator.generate("í…ŒìŠ¤íŠ¸", [MockPaper()], target_audience='general')
            
        result = await test_operation()
        
        # ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
        await monitor.stop_monitoring()
        
        # ì„±ëŠ¥ ë¦¬í¬íŠ¸ í™•ì¸
        report = optimizer.get_performance_report("test_operation")
        
        return result is not None and report['total_calls'] > 0
        
    async def _test_data_flow(self) -> bool:
        """ë°ì´í„° íë¦„ í…ŒìŠ¤íŠ¸"""
        # ë°ì´í„°ê°€ ì»´í¬ë„ŒíŠ¸ ê°„ì— ì˜¬ë°”ë¥´ê²Œ ì „ë‹¬ë˜ëŠ”ì§€ í™•ì¸
        paper_data = {
            'title': 'Data Flow Test Paper',
            'impact_factor': 7.5,
            'citations': 80
        }
        
        paper = MockPaper(**paper_data)
        
        # ë…¼ë¬¸ í‰ê°€
        evaluator = PaperQualityEvaluator()
        quality_info = evaluator.evaluate_paper(paper)
        
        # ì½˜í…ì¸  ìƒì„±
        generator = ArticleGenerator()
        content = generator.generate(
            "ë°ì´í„° íë¦„ í…ŒìŠ¤íŠ¸",
            [paper],
            target_audience='general'
        )
        
        # ìƒì„±ëœ ì½˜í…ì¸ ì— ë…¼ë¬¸ ì •ë³´ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨
        return paper_data['title'] in content.total_content
        
    # ì—£ì§€ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸ êµ¬í˜„
    async def _test_empty_inputs(self) -> bool:
        """ë¹ˆ ì…ë ¥ í…ŒìŠ¤íŠ¸"""
        tests = []
        
        # ë¹ˆ ì£¼ì œ
        generator = ShortsScriptGenerator()
        try:
            result = generator.generate("", [MockPaper()], target_audience='general')
            tests.append(result is not None)  # ê¸°ë³¸ê°’ì´ë‚˜ ì—ëŸ¬ ì²˜ë¦¬
        except:
            tests.append(True)  # ì˜ˆì™¸ ì²˜ë¦¬ë„ OK
            
        # ë¹ˆ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸
        try:
            result = generator.generate("í…ŒìŠ¤íŠ¸", [], target_audience='general')
            tests.append(result is not None)
        except:
            tests.append(True)
            
        return all(tests)
        
    async def _test_large_inputs(self) -> bool:
        """ëŒ€ìš©ëŸ‰ ì…ë ¥ í…ŒìŠ¤íŠ¸"""
        # ë§ì€ ë…¼ë¬¸
        large_paper_list = [MockPaper() for _ in range(100)]
        
        generator = ReportGenerator()
        try:
            result = generator.generate(
                "ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸",
                large_paper_list,
                target_audience='general'
            )
            return result is not None
        except:
            return False  # ëŒ€ìš©ëŸ‰ë„ ì²˜ë¦¬í•  ìˆ˜ ìˆì–´ì•¼ í•¨
            
    async def _test_special_characters(self) -> bool:
        """íŠ¹ìˆ˜ ë¬¸ì í…ŒìŠ¤íŠ¸"""
        special_chars = "!@#$%^&*()_+-=[]{}|;':\",./<>?â„¢â„ Â®Â©"
        
        generator = ArticleGenerator()
        result = generator.generate(
            f"íŠ¹ìˆ˜ë¬¸ì í…ŒìŠ¤íŠ¸ {special_chars}",
            [MockPaper(title=f"Paper with {special_chars}")],
            target_audience='general'
        )
        
        return result is not None and len(result.total_content) > 0
        
    async def _test_boundary_values(self) -> bool:
        """ê²½ê³„ê°’ í…ŒìŠ¤íŠ¸"""
        evaluator = PaperQualityEvaluator()
        
        boundary_papers = [
            MockPaper(impact_factor=0, citations=0),  # ìµœì†Œê°’
            MockPaper(impact_factor=999, citations=99999),  # ìµœëŒ€ê°’
            MockPaper(impact_factor=-1, citations=-10),  # ìŒìˆ˜
            MockPaper(impact_factor=None, citations=None)  # None
        ]
        
        for paper in boundary_papers:
            try:
                quality_info = evaluator.evaluate_paper(paper)
                # ëª¨ë“  ê²½ìš°ì— ëŒ€í•´ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨
            except:
                pass  # ì˜ˆì™¸ ì²˜ë¦¬ë„ OK
                
        return True
        
    def _generate_qa_report(self):
        """QA ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "=" * 80)
        print("ğŸ“Š QA í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 80)
        
        # ê²°ê³¼ ì§‘ê³„
        total_tests = len(self.test_results)
        passed = sum(1 for t in self.test_results if t['status'] == 'PASS')
        failed = sum(1 for t in self.test_results if t['status'] == 'FAIL')
        errors = sum(1 for t in self.test_results if t['status'] == 'ERROR')
        
        # ì„±ê³µë¥ 
        success_rate = (passed / total_tests * 100) if total_tests > 0 else 0
        
        print(f"\nì´ í…ŒìŠ¤íŠ¸: {total_tests}")
        print(f"âœ… ì„±ê³µ: {passed}")
        print(f"âŒ ì‹¤íŒ¨: {failed}")
        print(f"ğŸ’¥ ì—ëŸ¬: {errors}")
        print(f"ğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%")
        
        # ì‹¤íŒ¨/ì—ëŸ¬ ìƒì„¸
        if failed > 0 or errors > 0:
            print("\nâš ï¸ ì‹¤íŒ¨/ì—ëŸ¬ ìƒì„¸:")
            for test in self.test_results:
                if test['status'] in ['FAIL', 'ERROR']:
                    print(f"  - {test['test_name']}: {test['status']}")
                    if 'error' in test:
                        print(f"    Error: {test['error'][:100]}...")
                        
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        if self.test_results:
            avg_time = sum(t.get('execution_time', 0) for t in self.test_results) / len(self.test_results)
            print(f"\nâ±ï¸ í‰ê·  ì‹¤í–‰ ì‹œê°„: {avg_time:.2f}ì´ˆ")
            
        # ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥
        report_path = "./qa_report.json"
        report_data = {
            'summary': {
                'total_tests': total_tests,
                'passed': passed,
                'failed': failed,
                'errors': errors,
                'success_rate': success_rate,
                'timestamp': datetime.now().isoformat()
            },
            'test_results': self.test_results,
            'error_log': self.error_log
        }
        
        with open(report_path, 'w') as f:
            json.dump(report_data, f, indent=2)
            
        print(f"\nğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")


class MockPaper:
    """í…ŒìŠ¤íŠ¸ìš© ëª¨ì˜ ë…¼ë¬¸"""
    def __init__(self, **kwargs):
        self.title = kwargs.get('title', 'Test Paper')
        self.authors = kwargs.get('authors', 'Test Author')
        self.journal = kwargs.get('journal', 'Test Journal')
        self.year = kwargs.get('year', 2024)
        self.impact_factor = kwargs.get('impact_factor', 5.0)
        self.citations = kwargs.get('citations', 50)
        self.paper_type = kwargs.get('paper_type', 'Original Research')
        self.doi = kwargs.get('doi', 'test-doi-123')
        self.id = kwargs.get('id', 'test-id-123')


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
async def run_qa_tests():
    """QA í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    suite = QATestSuite()
    await suite.run_all_qa_tests()

if __name__ == "__main__":
    asyncio.run(run_qa_tests())